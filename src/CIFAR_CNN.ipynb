{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing will happen on  GPU\n"
     ]
    }
   ],
   "source": [
    "# Checking if GPU enabled\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if train_on_gpu:print(\"Processing will happen on  GPU\")\n",
    "else:print(\"Processing will happen on  CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Transform Object\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Downloading the Data\n",
    "train_data = datasets.CIFAR10(root='../data/CIFAR10/', train=True, download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10(root='../data/CIFAR10/', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definig Network Related Constants\n",
    "BATCH_SIZE = 20\n",
    "VALIDATION_SIZE =0.20\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data into train & Val set\n",
    "np.random.seed(10)\n",
    "total_sample = len(train_data)\n",
    "indices = list(range(total_sample))\n",
    "np.random.shuffle(indices)\n",
    "val_indices = int(VALIDATION_SIZE * total_sample)\n",
    "train_idx , val_idx = indices[val_indices:], indices[:val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing samplers\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading samples\n",
    "train_set = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "val_set = DataLoader(train_data, sampler=val_sampler, batch_size=BATCH_SIZE)\n",
    "test_set = DataLoader(test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set shape : 2000\n",
      "val_set shape : 500\n",
      "test_set shape : 500\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_set shape : {len(train_set)}\\nval_set shape : {len(val_set)}\\ntest_set shape : {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa0f0383f10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAcuklEQVR4nO2da4ykZ3Xn/6fu1dXdM93TnmFunhkbJxuWJAaNvOyCIpIokYMiGaQVAmmRP6BMFAVliZIPFnuBlfKBRAuIDytWw2LFWbFcNoCwViiB9UZiE0UOA2uMwVnHgIeZ8dx7+t5dl7fOfqgaaex9/qd7qrurHZ7/z7Km+j39vO/pp55Tb9Xzr3OOuTuEED/9lPbaASHEeFCwC5EJCnYhMkHBLkQmKNiFyAQFuxCZUNnOYDN7GMAnAZQB/Bd3/2j0+82pKd934EDauLFCx/WLHjnhNB1TrjeprQQuN26sLFPb+vJS8rj1+fk8eD21wA8zagpto0ippRI/YaXCl0ipXKa2bqeTPF4Nbi/VWo3aiqKgtlqF+1GvpC9YGB/Tq09yP2y0kKmWutQ2VU2v73bBr7VGbAvXrmJtcTH5hI4c7GZWBvCfAPwagIsAvmVmT7r7D9iYfQcO4F/923+XPt8Lf0OvtTF/LXm8//O/Qcfsf+CN1Fb3DWp74W//N7X94H99PXnc1smLEYC+8wVcKQULuNyntlKZB2evSC+q6AWiUec+zh2co7apySlqu/LyT5LH72nxJXfs6BFqu3VrkdpOHJyhtlP3pF/0F2vc95sn30ptC/WD1Ba9zB6pXaW2Xz56PXn8xWU+99+dT//NZ3//9+iY7byNfwjAi+7+I3fvAPg8gEe2cT4hxC6ynWA/CuDCHT9fHB4TQrwG2fUNOjM7Y2bnzOzc2jL/PCyE2F22E+yXABy/4+djw2OvwN3Puvtpdz89McU/JwkhdpftBPu3ADxgZqfMrAbgPQCe3Bm3hBA7zci78e7eM7MPAPhLDKS3x939++EgM5Tr1aSpOcmlsqlyeudxcYKPaQTvIur9tA8AUG/yc1op/doYyVNFn7+elo3v35aDHfdo99xKaVu9wX2cmdlHbdVaMG6Wj+u00zvJG4tpZQUAlpa4/Foicw8AEw0+HzNTreTxciDbrjQnqK3Z4uvKETxnFf63tVppSbcF7ke9k5YHo3nals7u7l8D8LXtnEMIMR70DTohMkHBLkQmKNiFyAQFuxCZoGAXIhO2tRt/17ij10snjRRFOksKAOo1kqEUSFdhVkJgK5V4NlR4zlEGBckplUhCCbLNSuX0uAMz++mY2QNcQnPw5wVRIg+TRdtc2ry5wJNdmkEWYzCNKNMMID6qKHgSUpRUGElv/SAzcn19PXm82+WZciy7MVqiurMLkQkKdiEyQcEuRCYo2IXIBAW7EJkw3t144+WRqmzHHUDd0rujZbLzDMS12Nz5rqkFNcbM2PX47q0F9aCiZJeoPl3R5WWwWDm5VqtBx7RaPJFkltUMBDC/tEZtZVL77fipU3TMhfMXqW11g5cS63a5KsDUn/V1fr5+P9qND3bcgzXXD57PleXV5PEOgt146iO/ju7sQmSCgl2ITFCwC5EJCnYhMkHBLkQmKNiFyISxSm/uXNbodtt03NRcuu7XcosnR3iYEsDlk41AkmEJEuXgfHGrJi7x9J3LSZE0VKnUk8erVe7IzAyvq3bvvYeprTGfrp0GALVGuvbbVCPtHwAUwb3n5Qtclptf4gk0vSLtR7fP5ctQmg2e6/D5DBJhWMJLvxzJx8QWJXlxkxDipwkFuxCZoGAXIhMU7EJkgoJdiExQsAuRCduS3szsJQDLAAoAPXc/Hf8+UK2ms9ump9MSCQBcv34leXypsUDHTB+K6oFRE+KKZmlbUC4OHmW9BeNKJNMPAIoerws3N3coefzEiePJ4wAwe4BLb502lyIPHUy35QKAuXvS7Z/WghZP9QmeEVep8cw8LPGWUosr6Ywym+Z/cyyvcTdKFtQGjGobjnDPHaUc4k7o7L/s7jd24DxCiF1Eb+OFyITtBrsD+LqZfdvMzuyEQ0KI3WG7b+Pf5u6XzOwggG+Y2d+7+zfv/IXhi8AZAJgOqp4IIXaXbd3Z3f3S8N9rAL4C4KHE75x199Pufro5le4pLYTYfUYOdjNrmdnU7ccAfh3AczvlmBBiZ9nO2/hDAL4yLKhYAfDf3P0vogE2/C9t5FITK8xY9O++PQ4QFY4ELHz9S/vR7/MMtUh6C2pbYnKSF4g8fJB/HJqZSbdyWlm6Rcesr3Gbg2eH3f96LpUdID6uLXEpr9rg7/yOnjxBbVf+nvu/uJYuitmvcj96vUCbDdZO0ePrIFpW5XJ6IUTFSkcR30YOdnf/EYBfHHW8EGK8SHoTIhMU7EJkgoJdiExQsAuRCQp2ITJh7L3eSiTVq1qt0mFtYzJDID9E6UlRZlsgrcTnTFMhPc8AoNnk0z8zM0FtB2Z5xlaJFClcXLhJx7Qm+bWaTV4gcmOdZ7CVPH3OXsH7wy21uXR1z0EuvV1vcJlybSOd9VYLCkB6YIsVr7vPmASAEllzsfR29+jOLkQmKNiFyAQFuxCZoGAXIhMU7EJkwnh342EwUrDNghpdvSK9S+tRrbDAiyLYVQ/bRpGEl6iWXKXKjY2gFdJUk9dcq4DXoCuTeaxO8msdO85bPFUrfIkUPb6z7sV68rgZ33G/cYPXkpucPkht07M8Mah/dTl5vBvkuvSDXfB+lGBVitYjtxVs9z8qWxfu/KfRnV2ITFCwC5EJCnYhMkHBLkQmKNiFyAQFuxCZMFbpzeHo9dI1zVZW01INAPT75DUpaLfTp8kzQC+wFc6loZKnfW/WeRKPBV2LDLyGXqkbJNA4/7snJ9NttI6fupeOOXGKJ5lc+Ml5altYbFMbkyMbDd7ma/7GBWqrlrkfPxu0trqxupg8vrDO5z7qDsaWIhDXPfTgrCwmilJ0vrtHd3YhMkHBLkQmKNiFyAQFuxCZoGAXIhMU7EJkwqbSm5k9DuA3AVxz9zcOj80C+AKAkwBeAvBud+c9eG7jjl6RliCCDkqwUlraGrVUWCTLRSNrRE86dphnZPUDWW594Tq1NYPadRNBJl0F6Yk8cYxntrUmuD7YDurMWfCkdTtpOalW5fXuukENuqX5JWqr3s9r0E3P3JM83l7hmYPzXS7LWSTbFrxVlkeSHTdxWGZekAy3lTv7nwJ4+FXHHgPwlLs/AOCp4c9CiNcwmwb7sN/6/KsOPwLgieHjJwC8c4f9EkLsMKN+Zj/k7peHj69g0NFVCPEaZtsbdD74jiD92GFmZ8zsnJmdW1vmn/+EELvLqMF+1cwOA8DwX1pPyN3Puvtpdz89McX7bwshdpdRg/1JAI8OHz8K4Ks7444QYrfYivT2OQBvBzBnZhcBfBjARwF80czeD+A8gHdv5WJ9d3Q6acljfWODjmsRPcGD9CQLNIhIeasExQabpPji4bm0vAMAb/oX/4zarpx/kdp68xepbW6Oy1c3V9JZXh5M1uQkf8c1McGz1PpBhqCV0nLe6hqXvHo9PvcXL16htgsHL1Fbo5/Opux1+SKoBEU2eyO2f+r3+fz3LW2LsuhGYdNgd/f3EtOv7qgnQohdRd+gEyITFOxCZIKCXYhMULALkQkKdiEyYby93hwoSNZbpDL0yRf0Ymkikt6CzLag51yN9KnrrPOeZ8vzN6mt3+ZFNvdPNqltZv80ta120+dcWExLcgBw+Ngxapto8Wutt7mM1umm578o+PyWguqcN69x6e3HP+TFKF9/ZCZ5vN7g8mUnkN66Ua+3qP1aYKvV0n93iaw3gEt5UUjozi5EJijYhcgEBbsQmaBgFyITFOxCZIKCXYhMGK/0BoBpEEUvKF7YTxfyc+d6RiRBRBlx5UA/KRPTrRs0nR/PP/cstR2Y4NN/6sQctU00eBHL1kRasltZWaZjOl1eKLFc4XJYJ0gB6y6nsxg32vz+0g0y0VaWuUx54TzvEXdwIi31tV7Hs/kiSddKQWZbMB8eZL2N4scoGXG6swuRCQp2ITJBwS5EJijYhcgEBbsQmTD23Xgjry+Li3y3uE3qiOH4aLvx8U5mUJuMbMevr3Lfr1ziu8hHf+4Bajt88AC1ocTPWSWtoXrBjvvS8iq1La/wa62u8kQYdNJztbLCn7O1tTa1dSP/F3hrqFvz6a5k1Vk+v1G9uEjJ6Qf9yKKWY13Sbqpf5X5oN14IQVGwC5EJCnYhMkHBLkQmKNiFyAQFuxCZsJX2T48D+E0A19z9jcNjHwHwWwCuD3/tQ+7+ta1dMi1dXLvGk0mq3bQ0NPdPR5PeiigpIUiEqVbTSSENXlYNfeMJPvv38WSMA7NT1NbhKhSKy2kZpxJIipevXKW28z/hbaiiBJrWTLrG28YGl/KYBAUAHshazUaD2tjdLJLXWE04ANjo8b85qkFXqfBFUi6nbRacMLIxtnJn/1MADyeOf8LdHxz+v8VAF0LsFZsGu7t/E8D8GHwRQuwi2/nM/gEze9bMHjezdL1eIcRrhlGD/VMA7gfwIIDLAD7GftHMzpjZOTM7t76yMuLlhBDbZaRgd/er7l74oOn3pwE8FPzuWXc/7e6nm0EfcCHE7jJSsJvZ4Tt+fBeA53bGHSHEbrEV6e1zAN4OYM7MLgL4MIC3m9mDGKSIvQTgt7d6QZYZdPQIb0HU6Kfrma1FLZ4seB0LZIs+uCTT7aeloZV1nnXV2sfbOHXavG1Ue4PbKjUuQ1WJxFMUXALstLnktbDAM/rWOzxLrTqZlg5vLS7QMVGdvFJQ+61R58u4NZGW5Vot3v5pIZirKCsyIsqIY9Jb1P5plKy3TYPd3d+bOPyZu76SEGJP0TfohMgEBbsQmaBgFyITFOxCZIKCXYhMGGvBSbMSGiRDaWL/Pjpu/UZahooylyJponA+rkdaTQFclpvcx78stG92mto6PV6wsd3m2WG9gvvIpLdKk0uA0/v3U1upzJdIsxlkclXS4zbaaRkVANbWuNxYrfJrRRllU5PpzMKJYD5uhNJbVHAyyKYMbqtsrY62vvm6151diExQsAuRCQp2ITJBwS5EJijYhcgEBbsQmTBm6c1QKqUvubyU7skFADeupQsitn6GSyQeySAeFOsrcRmnXk/LhifuPUTHHD/Fs/mK1ZvUNr/As8OmJoOnjUgytUCemiaZYQAw0ahSW8f5/Hd76Yy49gbPlOt1+HPWKvMikBNBgchmnf3dwfoI5CuPbFF/weC+aiQMPVin7FqRD7qzC5EJCnYhMkHBLkQmKNiFyAQFuxCZMNbdeDjoJmi1HHyBv5zelexbtKPKd4oteI2rkHpgAFAn7Z9aEzwRplypU9t6n++23gxqv5XLvH5a0Uv/3ZNB4sdEg+9mt5p8N77fCRJGyBS32zz5xwu+BiaafB4nm9z/comtkShpha+PIqglFyXJhDvrrF5ipBqNgO7sQmSCgl2ITFCwC5EJCnYhMkHBLkQmKNiFyISttH86DuDPABzCQDw76+6fNLNZAF8AcBKDFlDvdneezXIbolwcPfK6wMm0THI9VCaiWlzcVolqhZHkmiuX04k6APDjy5eobWaaS0a1WZ6c0mzwp63bS/9t+/fP0jHloLVSKZBE64HkVZlIy4MbbZ4IEz0v+6bSteQAYGYft3lBrhe0B4uk2aguXCkYV/S5TNlnNgsza+6ardzZewD+wN3fAOAtAH7XzN4A4DEAT7n7AwCeGv4shHiNsmmwu/tld//O8PEygOcBHAXwCIAnhr/2BIB37paTQojtc1ef2c3sJIA3AXgawCF3vzw0XcHgbb4Q4jXKloPdzCYBfAnAB939FT2KfVDEOvkpwszOmNk5Mzu3tsxbGwshdpctBbuZVTEI9M+6+5eHh6+a2eGh/TCAa6mx7n7W3U+7++mJKd4wQQixu2wa7GZmGPRjf97dP36H6UkAjw4fPwrgqzvvnhBip9hK1ttbAbwPwPfM7JnhsQ8B+CiAL5rZ+wGcB/DurVxw8Nrx/7OywrO8VldXt3LqVxC1f7Kg/VM1kKE6G+mWTD++cTl5HAAWSS02AHj9/cepbbrK/W/W+NNWqqezw0pVnjV2a4l/vFpc4bbZI0f4OdfT2W2ra/x5btT5vefokTlqO3aEt6/aWLqSPr7MW035oUDTDTLR+sG6cgvaink3PWbEeneMTYPd3f8aPHfvV+/+kkKIvUDfoBMiExTsQmSCgl2ITFCwC5EJCnYhMmGsBSfdHZ1OWpKJ2gK1Wumspo2gMGCoTQQZSLVa0CZpX/pLQW1wWaVb8Oy1ThHIfM6fmkpzH7WtddPzuLTG5/f6Ak9W7BZcTrIKL0a5tJo+50Zng445eIhLaKdO8KzII6/jBT9f7qRbbL1wkculOMqLYtokX3OOtIQ2gK+5okhfr18K2puNkPamO7sQmaBgFyITFOxCZIKCXYhMULALkQkKdiEyYezSW7eblifYcYBn4UTF/zbzgxu5qSAylAc9vianuZwUtDZDmxSOBIDrSzwLcKOblnGuzfPstfnlFWq7FVxrMpDz1tbSEtuhgwfpmJ+79z5qm5riWXur6zyTriDPdbnCl34vWFYsaxMA+kEfOAuyKcvl9D3XgnW1WwUnhRA/BSjYhcgEBbsQmaBgFyITFOxCZMJ4d+PhdCe8HbQFKgc7oJSwjBh/jQs2wbHRSSsGRZcnwkw1022QAKBe437USPskAGgHddBuLqV31i9cSRb/BQAsBDXo1tt8a3p9g//dPbKlff/Je+mYg7Ncueh00vX/AKBb8Hpya+20j6UyT3gqBTvnvai2YbDoRqkZF616JcIIISgKdiEyQcEuRCYo2IXIBAW7EJmgYBciEzaV3szsOIA/w6AlswM46+6fNLOPAPgtANeHv/ohd/9aeC4YTSSIklOYJRwT5boE0luUgNLukJpgQeZEtcqneGqqSW2BuobaZLomHwBUSYuq+UWe0HLzFk8ksTKXAIuCy1e1cro+3Uzgey+Q19ZWeLJOrcIna4M8ZZWg1iCqfH10guSrOHGFn7MgPnrg4ihsRWfvAfgDd/+OmU0B+LaZfWNo+4S7/8eddUkIsRtspdfbZQCXh4+Xzex5AEd32zEhxM5yV5/ZzewkgDcBeHp46ANm9qyZPW5mMzvsmxBiB9lysJvZJIAvAfiguy8B+BSA+wE8iMGd/2Nk3BkzO2dm59aDtsxCiN1lS8FuZlUMAv2z7v5lAHD3q+5euHsfwKcBPJQa6+5n3f20u59uTk7tlN9CiLtk02C3wfb5ZwA87+4fv+P44Tt+7V0Antt594QQO8VWduPfCuB9AL5nZs8Mj30IwHvN7EEMlLGXAPz2ZidyOK0b12hyGapC5LqFzS5IKMA1jVWSJQUA66R11QSpIQYA5UCNKYPLOFeuXqW2mcP3UNt9P/OzyeO3FnhmW6XG2x1Va7x9VQk1aptqpCW2zhqXAHtBHcKizX1Emct5lUa6NdTUNH+XuRxIeR48Z6H0Ft1XmcYW6K8j5IFuaTf+r8m5Q01dCPHaQt+gEyITFOxCZIKCXYhMULALkQkKdiEyYawFJwGA1Y6M2upwoSHKegvS3oxLb+sssw3AMml3NDvLpR8EUs3GGv9GYbvNiyhevcGLR87OpdsrTe7jr+vVOpeh+kHqlQV/275WelytxSXWTpDZtgIu2XULvnZak+kilpUpns23BC6/hus0ksqCNVdituBaI9Sv1J1diFxQsAuRCQp2ITJBwS5EJijYhcgEBbsQmTBm6c2BUjp7KeqxZsRWNi6RoM9PWAlkuUogalglbZto1emYiTq3ra/yAov1Bu97tr7GJa+XL11KHu8GPdted+gktbWDTLSL51+gtvuPzCWPNxp8PrrB3E8HUlmpxM85tz+d9VZMcbnxeoXLZM6V2RDv86y9eiP93JSia0UVSQm6swuRCQp2ITJBwS5EJijYhcgEBbsQmaBgFyITxiq9mQFlIl+B9AYDAO+mpQkLJDQLXsfKgWxRCuSfejPt40SQyVWt8CleDnrEocKLOV67cpPaNlYW034YPx863MdOwSWj3jrP2ivW04Uqvczndz+RyYB4HstBZt6BfemMxP7+fXRMZT0Ii0jyikzGdbR9+9Pr58oS98OZH4GErTu7EJmgYBciExTsQmSCgl2ITFCwC5EJm+7Gm1kDwDcB1Ie//+fu/mEzOwXg8wAOAPg2gPe5e9CjZ7BRWJAElV4vqLfVZTuPo9Sti4lGVUiCRLXOd7o7bZ5IsrrGE2FQ5jv1S0ELpTrZdS/X+G7wtZcvUFuJiyRokQQOAOh3N5LH3flctVrT1FYu8ftSxbmtROrJ1YKEnNLGaHXmEKlDwbB6PT3J0d88Cls5WxvAr7j7L2LQnvlhM3sLgD8G8Al3fz2AWwDev6OeCSF2lE2D3QfcLvtZHf7vAH4FwJ8Pjz8B4J274qEQYkfYan/28rCD6zUA3wDwQwAL7n77PdJFAEd3x0UhxE6wpWB398LdHwRwDMBDAP7JVi9gZmfM7JyZndsI6oILIXaXu9oBcPcFAH8F4J8D2G9mtzf4jgFIlkhx97PuftrdTzcm+dchhRC7y6bBbmb3mNn+4eMmgF8D8DwGQf8vh7/2KICv7paTQojts5VEmMMAnrBB/5oSgC+6+/8wsx8A+LyZ/RGA/wPgM5ueyYEeKRu3fIMnVVSJelW5L0ieCV7H+lGduUAjsVJaeut0eC28laDO3NpaWp4aXCtIkim4/3P707Xr6mU+HyvL3I9GlUtlzRqfq2otfb16nS85K/G/K2qH1QvksKql10i9NFprpcgWi73B9ahkN0qTJ86mwe7uzwJ4U+L4jzD4/C6E+EeAvkEnRCYo2IXIBAW7EJmgYBciExTsQmSC8W3/XbiY2XUA54c/zgG4MbaLc+THK5Efr+Qfmx8n3P2elGGswf6KC5udc/fTe3Jx+SE/MvRDb+OFyAQFuxCZsJfBfnYPr30n8uOVyI9X8lPjx559ZhdCjBe9jRciE/Yk2M3sYTP7v2b2opk9thc+DP14ycy+Z2bPmNm5MV73cTO7ZmbP3XFs1sy+YWb/MPx3Zo/8+IiZXRrOyTNm9o4x+HHczP7KzH5gZt83s389PD7WOQn8GOucmFnDzP7OzL479OM/DI+fMrOnh3HzBbOop1cCdx/r/wDKGJS1ug9ADcB3Abxh3H4MfXkJwNweXPeXALwZwHN3HPsTAI8NHz8G4I/3yI+PAPjDMc/HYQBvHj6eAvACgDeMe04CP8Y6Jxjkw04OH1cBPA3gLQC+COA9w+P/GcDv3M159+LO/hCAF939Rz4oPf15AI/sgR97hrt/E8D8qw4/gkHhTmBMBTyJH2PH3S+7+3eGj5cxKI5yFGOek8CPseIDdrzI614E+1EAdxYq38tilQ7g62b2bTM7s0c+3OaQu18ePr4C4NAe+vIBM3t2+DZ/1z9O3ImZncSgfsLT2MM5eZUfwJjnZDeKvOa+Qfc2d38zgN8A8Ltm9kt77RAweGXHTpcp2TqfAnA/Bj0CLgP42LgubGaTAL4E4IPuvnSnbZxzkvBj7HPi2yjyytiLYL8E4PgdP9NilbuNu18a/nsNwFewt5V3rprZYQAY/nttL5xw96vDhdYH8GmMaU7MrIpBgH3W3b88PDz2OUn5sVdzMrz2XRd5ZexFsH8LwAPDncUagPcAeHLcTphZy8ymbj8G8OsAnotH7SpPYlC4E9jDAp63g2vIuzCGObFB4b/PAHje3T9+h2msc8L8GPec7FqR13HtML5qt/EdGOx0/hDAv9kjH+7DQAn4LoDvj9MPAJ/D4O1gF4PPXu/HoGfeUwD+AcD/BDC7R378VwDfA/AsBsF2eAx+vA2Dt+jPAnhm+P87xj0ngR9jnRMAv4BBEddnMXhh+fd3rNm/A/AigP8OoH4359U36ITIhNw36ITIBgW7EJmgYBciExTsQmSCgl2ITFCwC5EJCnYhMkHBLkQm/D+bMZ+4iAvciAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#analyze the data\n",
    "images, labels = next(iter(train_set))\n",
    "images = images.numpy()\n",
    "plt.imshow(np.transpose((images[0]/2 + 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Definig the network architecture\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        #defining convolution layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)#as we are going with square kernels\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64*4*4, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64*4*4)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        out = self.fc2(x)\n",
    "        return out\n",
    "\n",
    "network  = Net()\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moving operations to cuda\n",
    "if train_on_gpu:\n",
    "    network.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the loss of the system\n",
    "criterian = nn.CrossEntropyLoss()\n",
    "#defining the optimizer\n",
    "optimizer = optim.SGD(params=network.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs : 2\n",
      "training_loss: 0.08634433728694915\n",
      "validation_loss: 0.09620899842977523\n",
      "validation loss decreased from inf to 0.09620899842977523now saving the model\n",
      "Epochs : 3\n",
      "training_loss: 0.06939769218444825\n",
      "validation_loss: 0.07661415812969208\n",
      "validation loss decreased from 0.09620899842977523 to 0.07661415812969208now saving the model\n",
      "Epochs : 4\n",
      "training_loss: 0.06010369188427925\n",
      "validation_loss: 0.06969956650137901\n",
      "validation loss decreased from 0.07661415812969208 to 0.06969956650137901now saving the model\n",
      "Epochs : 5\n",
      "training_loss: 0.055463853368759156\n",
      "validation_loss: 0.06496157277226448\n",
      "validation loss decreased from 0.06969956650137901 to 0.06496157277226448now saving the model\n",
      "Epochs : 6\n",
      "training_loss: 0.051340725234746934\n",
      "validation_loss: 0.05907432153224945\n",
      "validation loss decreased from 0.06496157277226448 to 0.05907432153224945now saving the model\n",
      "Epochs : 7\n",
      "training_loss: 0.04809940950810909\n",
      "validation_loss: 0.05654735181927681\n",
      "validation loss decreased from 0.05907432153224945 to 0.05654735181927681now saving the model\n",
      "Epochs : 8\n",
      "training_loss: 0.045199861315488817\n",
      "validation_loss: 0.05235058399736881\n",
      "validation loss decreased from 0.05654735181927681 to 0.05235058399736881now saving the model\n",
      "Epochs : 9\n",
      "training_loss: 0.04256695321679115\n",
      "validation_loss: 0.050010438933968546\n",
      "validation loss decreased from 0.05235058399736881 to 0.050010438933968546now saving the model\n",
      "Epochs : 10\n",
      "training_loss: 0.04028565581262112\n",
      "validation_loss: 0.047400198471546175\n",
      "validation loss decreased from 0.050010438933968546 to 0.047400198471546175now saving the model\n",
      "Epochs : 11\n",
      "training_loss: 0.0383458198338747\n",
      "validation_loss: 0.04535277800261974\n",
      "validation loss decreased from 0.047400198471546175 to 0.04535277800261974now saving the model\n"
     ]
    }
   ],
   "source": [
    "valid_loss_min = np.Inf\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    training_loss = 0\n",
    "    validation_loss = 0\n",
    "    ##################\n",
    "    #TRAINING MODE####\n",
    "    ##################\n",
    "    network.train()#Model layers will know that training is going on\n",
    "    \n",
    "    for images, labels in train_set:\n",
    "        \n",
    "        if train_on_gpu:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = network.forward(images)\n",
    "        loss = criterian(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss += loss.item()\n",
    "        \n",
    "    #####################\n",
    "    ##VALIDATION MODE####\n",
    "    #####################\n",
    "    network.eval()\n",
    "    \n",
    "    for images, labels in val_set:\n",
    "        \n",
    "        if train_on_gpu:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "        output = network.forward(images)\n",
    "        loss = criterian(output, labels)\n",
    "        validation_loss += loss.item()\n",
    "        \n",
    "    #calculating average loss\n",
    "    average_train_loss = training_loss / len(train_data)\n",
    "    average_val_loss = validation_loss / val_indices\n",
    "    \n",
    "    print(f\"Epochs : {epoch+1}\\ntraining_loss: {average_train_loss}\\nvalidation_loss: {average_val_loss}\")\n",
    "    \n",
    "    #save model when balidation loss decreases\n",
    "    if average_val_loss <= valid_loss_min:\n",
    "        print(f\"validation loss decreased from {valid_loss_min} to {average_val_loss}now saving the model\")\n",
    "        torch.save(network.state_dict(),'../out/model_cifar10.pt')\n",
    "        valid_loss_min = average_val_loss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the model with lowest validation loss\n",
    "network.load_state_dict(torch.load('../out/model_cifar10.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average test loss : 0.045437425914406776\n"
     ]
    }
   ],
   "source": [
    "#Testing the model against the test set\n",
    "test_loss = 0\n",
    "class_correct = list(0 for i in range(10))\n",
    "class_total = list(0 for i in range(10))\n",
    "network.eval()\n",
    "for images, labels in test_set:\n",
    "    if train_on_gpu:\n",
    "        images, labels  = images.cuda(), labels.cuda()\n",
    "    output = network.forward(images)\n",
    "    loss = criterian(output, labels)\n",
    "    test_loss += loss.item()\n",
    "    #convert output probabilities to predicted cloud\n",
    "    _, pred = torch.max(output, 1)\n",
    "    #compare with true labels\n",
    "    correct_tensor = pred.eq(labels.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "    for i in range(BATCH_SIZE):\n",
    "        label = labels[i].item()\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] +=1\n",
    "#average test loss\n",
    "average_test_loss = test_loss/len(test_data)\n",
    "print(f\"average test loss : {average_test_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
