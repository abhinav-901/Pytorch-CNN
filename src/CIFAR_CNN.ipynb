{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing will happen on  GPU\n"
     ]
    }
   ],
   "source": [
    "# Checking if GPU enabled\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if train_on_gpu:print(\"Processing will happen on  GPU\")\n",
    "else:print(\"Processing will happen on  CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Transform Object\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Downloading the Data\n",
    "train_data = datasets.CIFAR10(root='../../../temp_data/', train=True, download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10(root='../../../temp_data/', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definig Network Related Constants\n",
    "BATCH_SIZE = 20\n",
    "VALIDATION_SIZE =0.20\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data into train & Val set\n",
    "np.random.seed(10)\n",
    "total_sample = len(train_data)\n",
    "indices = list(range(total_sample))\n",
    "np.random.shuffle(indices)\n",
    "val_indices = int(VALIDATION_SIZE * total_sample)\n",
    "train_idx , val_idx = indices[val_indices:], indices[:val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing samplers\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading samples\n",
    "train_set = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "val_set = DataLoader(train_data, sampler=val_sampler, batch_size=BATCH_SIZE)\n",
    "test_set = DataLoader(test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set shape : 2000\n",
      "val_set shape : 500\n",
      "test_set shape : 500\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_set shape : {len(train_set)}\\nval_set shape : {len(val_set)}\\ntest_set shape : {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6ac06cd8d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#analyze the data\n",
    "images, labels = next(iter(train_set))\n",
    "images = images.numpy()\n",
    "plt.imshow(np.transpose((images[0]/2 + 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Definig the network architecture\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        #defining convolution layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)#as we are going with square kernels\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64*4*4, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64*4*4)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        out = self.fc2(x)\n",
    "        return out\n",
    "\n",
    "network  = Net()\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moving operations to cuda\n",
    "if train_on_gpu:\n",
    "    network.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the loss of the system\n",
    "criterian = nn.CrossEntropyLoss()\n",
    "#defining the optimizer\n",
    "optimizer = optim.SGD(params=network.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs : 1\n",
      "training_loss: 0.105105\n",
      "validation_loss: 0.091367\n",
      "validation loss decreased from inf to 0.091367now saving the model\n",
      "Epochs : 2\n",
      "training_loss: 0.083686\n",
      "validation_loss: 0.074021\n",
      "validation loss decreased from 0.091367 to 0.074021now saving the model\n",
      "Epochs : 3\n",
      "training_loss: 0.072926\n",
      "validation_loss: 0.066316\n",
      "validation loss decreased from 0.074021 to 0.066316now saving the model\n",
      "Epochs : 4\n",
      "training_loss: 0.066589\n",
      "validation_loss: 0.062757\n",
      "validation loss decreased from 0.066316 to 0.062757now saving the model\n",
      "Epochs : 5\n",
      "training_loss: 0.061352\n",
      "validation_loss: 0.056841\n",
      "validation loss decreased from 0.062757 to 0.056841now saving the model\n",
      "Epochs : 6\n",
      "training_loss: 0.057118\n",
      "validation_loss: 0.053549\n",
      "validation loss decreased from 0.056841 to 0.053549now saving the model\n",
      "Epochs : 7\n",
      "training_loss: 0.053560\n",
      "validation_loss: 0.050522\n",
      "validation loss decreased from 0.053549 to 0.050522now saving the model\n",
      "Epochs : 8\n",
      "training_loss: 0.050481\n",
      "validation_loss: 0.048016\n",
      "validation loss decreased from 0.050522 to 0.048016now saving the model\n",
      "Epochs : 9\n",
      "training_loss: 0.048012\n",
      "validation_loss: 0.045794\n",
      "validation loss decreased from 0.048016 to 0.045794now saving the model\n",
      "Epochs : 10\n",
      "training_loss: 0.045496\n",
      "validation_loss: 0.044524\n",
      "validation loss decreased from 0.045794 to 0.044524now saving the model\n"
     ]
    }
   ],
   "source": [
    "valid_loss_min = np.Inf\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    training_loss = 0\n",
    "    validation_loss = 0\n",
    "    ##################\n",
    "    #TRAINING MODE####\n",
    "    ##################\n",
    "    network.train()#Model layers will know that training is going on\n",
    "    \n",
    "    for images, labels in train_set:\n",
    "        \n",
    "        if train_on_gpu:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = network.forward(images)\n",
    "        loss = criterian(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss += loss.item()\n",
    "        \n",
    "    #####################\n",
    "    ##VALIDATION MODE####\n",
    "    #####################\n",
    "    network.eval()\n",
    "    \n",
    "    for images, labels in val_set:\n",
    "        \n",
    "        if train_on_gpu:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "        output = network.forward(images)\n",
    "        loss = criterian(output, labels)\n",
    "        validation_loss += loss.item()\n",
    "        \n",
    "    #calculating average loss\n",
    "    training_loss = training_loss / len(train_set.sampler)\n",
    "    validation_loss = validation_loss / len(val_set.sampler)\n",
    "    \n",
    "    print(f\"Epochs : {epoch}\\ntraining_loss: {training_loss:.6f}\\nvalidation_loss: {validation_loss:.6f}\")\n",
    "    \n",
    "    #save model when balidation loss decreases\n",
    "    if validation_loss <= valid_loss_min:\n",
    "        print(f\"validation loss decreased from {valid_loss_min:.6f} to {validation_loss:.6f}now saving the model\")\n",
    "        torch.save(network.state_dict(),'../out/model_cifar10_Without_AUG.pt')\n",
    "        valid_loss_min = validation_loss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the model with lowest validation loss\n",
    "network.load_state_dict(torch.load('../out/model_cifar10.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average test loss : 0.050559139090776445\n"
     ]
    }
   ],
   "source": [
    "#Testing the model against the test set\n",
    "test_loss = 0\n",
    "class_correct = list(0 for i in range(10))\n",
    "class_total = list(0 for i in range(10))\n",
    "network.eval()\n",
    "for images, labels in test_set:\n",
    "    if train_on_gpu:\n",
    "        images, labels  = images.cuda(), labels.cuda()\n",
    "    output = network.forward(images)\n",
    "    loss = criterian(output, labels)\n",
    "    test_loss += loss.item()\n",
    "    #convert output probabilities to predicted cloud\n",
    "    _, pred = torch.max(output, 1)\n",
    "    #compare with true labels\n",
    "    correct_tensor = pred.eq(labels.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "    for i in range(BATCH_SIZE):\n",
    "        label = labels[i].item()\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] +=1\n",
    "#average test loss\n",
    "average_test_loss = test_loss/len(test_set.sampler)\n",
    "print(f\"average test loss : {average_test_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
