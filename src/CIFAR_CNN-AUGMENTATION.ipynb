{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing will happen on  GPU\n"
     ]
    }
   ],
   "source": [
    "# Checking if GPU enabled\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if train_on_gpu:print(\"Processing will happen on  GPU\")\n",
    "else:print(\"Processing will happen on  CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Transform Object\n",
    "transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                               transforms.RandomRotation(10),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Downloading the Data\n",
    "train_data = datasets.CIFAR10(root='../../../temp_data/', train=True, download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10(root='../../../temp_data/', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definig Network Related Constants\n",
    "BATCH_SIZE = 20\n",
    "VALIDATION_SIZE =0.20\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data into train & Val set\n",
    "np.random.seed(10)\n",
    "total_sample = len(train_data)\n",
    "indices = list(range(total_sample))\n",
    "np.random.shuffle(indices)\n",
    "val_indices = int(VALIDATION_SIZE * total_sample)\n",
    "train_idx , val_idx = indices[val_indices:], indices[:val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing samplers\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading samples\n",
    "train_set = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "val_set = DataLoader(train_data, sampler=val_sampler, batch_size=BATCH_SIZE)\n",
    "test_set = DataLoader(test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set shape : 2000\n",
      "val_set shape : 500\n",
      "test_set shape : 500\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_set shape : {len(train_set)}\\nval_set shape : {len(val_set)}\\ntest_set shape : {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f76e044d950>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#analyze the data\n",
    "images, labels = next(iter(train_set))\n",
    "images = images.numpy()\n",
    "plt.imshow(np.transpose((images[0]/2 + 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Definig the network architecture\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        #defining convolution layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)#as we are going with square kernels\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64*4*4, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64*4*4)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        out = self.fc2(x)\n",
    "        return out\n",
    "\n",
    "network  = Net()\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moving operations to cuda\n",
    "if train_on_gpu:\n",
    "    network.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the loss of the system\n",
    "criterian = nn.CrossEntropyLoss()\n",
    "#defining the optimizer\n",
    "optimizer = optim.SGD(params=network.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs : 1\n",
      "training_loss: 0.107833\n",
      "validation_loss: 0.093983\n",
      "validation loss decreased from inf to 0.093983now saving the model\n",
      "Epochs : 2\n",
      "training_loss: 0.087179\n",
      "validation_loss: 0.077561\n",
      "validation loss decreased from 0.093983 to 0.077561now saving the model\n",
      "Epochs : 3\n",
      "training_loss: 0.076477\n",
      "validation_loss: 0.070394\n",
      "validation loss decreased from 0.077561 to 0.070394now saving the model\n",
      "Epochs : 4\n",
      "training_loss: 0.070846\n",
      "validation_loss: 0.067464\n",
      "validation loss decreased from 0.070394 to 0.067464now saving the model\n",
      "Epochs : 5\n",
      "training_loss: 0.066867\n",
      "validation_loss: 0.063155\n",
      "validation loss decreased from 0.067464 to 0.063155now saving the model\n",
      "Epochs : 6\n",
      "training_loss: 0.063507\n",
      "validation_loss: 0.058341\n",
      "validation loss decreased from 0.063155 to 0.058341now saving the model\n",
      "Epochs : 7\n",
      "training_loss: 0.060272\n",
      "validation_loss: 0.056338\n",
      "validation loss decreased from 0.058341 to 0.056338now saving the model\n",
      "Epochs : 8\n",
      "training_loss: 0.057859\n",
      "validation_loss: 0.055039\n",
      "validation loss decreased from 0.056338 to 0.055039now saving the model\n",
      "Epochs : 9\n",
      "training_loss: 0.055578\n",
      "validation_loss: 0.052443\n",
      "validation loss decreased from 0.055039 to 0.052443now saving the model\n",
      "Epochs : 10\n",
      "training_loss: 0.053421\n",
      "validation_loss: 0.050501\n",
      "validation loss decreased from 0.052443 to 0.050501now saving the model\n"
     ]
    }
   ],
   "source": [
    "valid_loss_min = np.Inf\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    training_loss = 0\n",
    "    validation_loss = 0\n",
    "    ##################\n",
    "    #TRAINING MODE####\n",
    "    ##################\n",
    "    network.train()#Model layers will know that training is going on\n",
    "    \n",
    "    for images, labels in train_set:\n",
    "        \n",
    "        if train_on_gpu:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = network.forward(images)\n",
    "        loss = criterian(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss += loss.item()\n",
    "        \n",
    "    #####################\n",
    "    ##VALIDATION MODE####\n",
    "    #####################\n",
    "    network.eval()\n",
    "    \n",
    "    for images, labels in val_set:\n",
    "        \n",
    "        if train_on_gpu:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "        output = network.forward(images)\n",
    "        loss = criterian(output, labels)\n",
    "        validation_loss += loss.item()\n",
    "        \n",
    "    #calculating average loss\n",
    "    training_loss = training_loss / len(train_set.sampler)\n",
    "    validation_loss = validation_loss / len(val_set.sampler)\n",
    "    \n",
    "    print(f\"Epochs : {epoch}\\ntraining_loss: {training_loss:.6f}\\nvalidation_loss: {validation_loss:.6f}\")\n",
    "    \n",
    "    #save model when balidation loss decreases\n",
    "    if validation_loss <= valid_loss_min:\n",
    "        print(f\"validation loss decreased from {valid_loss_min:.6f} to {validation_loss:.6f}now saving the model\")\n",
    "        torch.save(network.state_dict(),'../out/model_cifar10.pt')\n",
    "        valid_loss_min = validation_loss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the model with lowest validation loss\n",
    "network.load_state_dict(torch.load('../out/model_cifar10.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average test loss : 0.0499835362225771\n"
     ]
    }
   ],
   "source": [
    "#Testing the model against the test set\n",
    "test_loss = 0\n",
    "class_correct = list(0 for i in range(10))\n",
    "class_total = list(0 for i in range(10))\n",
    "network.eval()\n",
    "for images, labels in test_set:\n",
    "    if train_on_gpu:\n",
    "        images, labels  = images.cuda(), labels.cuda()\n",
    "    output = network.forward(images)\n",
    "    loss = criterian(output, labels)\n",
    "    test_loss += loss.item()\n",
    "    #convert output probabilities to predicted cloud\n",
    "    _, pred = torch.max(output, 1)\n",
    "    #compare with true labels\n",
    "    correct_tensor = pred.eq(labels.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "    for i in range(BATCH_SIZE):\n",
    "        label = labels[i].item()\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] +=1\n",
    "#average test loss\n",
    "average_test_loss = test_loss/len(test_set.sampler)\n",
    "print(f\"average test loss : {average_test_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
